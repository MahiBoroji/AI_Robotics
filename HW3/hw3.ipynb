{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2a0be9c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw3.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fc69dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add0ff4-27fa-4b8b-9429-77a6e70eb204",
   "metadata": {},
   "source": [
    "# FILL IN YOUR NAME AND THE NAME OF YOUR PEER (IF ANY) BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114b0f41-932d-43fb-96b0-a10ea759b6e4",
   "metadata": {},
   "source": [
    "**Name**: Maede Boroji\n",
    "\n",
    "**Peer**: Vahid Danesh\n",
    "\n",
    "## Collaboration policy\n",
    "Students are responsible for writing their own quizzes, assignments, and exams. For homework assignments, students are welcome (and encouraged) to discuss problems with one peer, **but each student must write their own assignment wrtieup and code individually**. The peer must be listed at the top of the writeup for each assignment. *Note: I will treat AI assistants as peers. That is, students are welcome to discuss problems with an AI assistant, but it is considered cheating to directly obtain an answer by querying the assistant. Please credit any AI assistant that you use.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeaa842-e2ff-4f0d-9447-6450943e8703",
   "metadata": {},
   "source": [
    "# Homework 3 -- Coordinate transformations (100 pts)\n",
    "\n",
    "**Due:** Tuesday, February 18th, 2025 at 11:59 pm\n",
    "\n",
    "This homework builds on the material in the slides, Hauser Chapters 3 and 4 (on Coordinate Transformations and 3D Rotations), and Tedrake chapter 3 (on Basic Pick-and-Place, especially 3.1 and 3.3).\n",
    "\n",
    "We will use Jupyter/Colab notebooks throughout the semester for writing code and generating assignment outputs.\n",
    "\n",
    "**Throughout this homework, please use 2D numpy arrays to represent all matrices. The autograder will use a precision of 3 decimal places.**\n",
    "\n",
    "\n",
    "## 1) Calculating Rotations and Homogeneous Transformations (30 pts)\n",
    "\n",
    "We will start by practicing how to construct rotation matrices and homogeneous transformation matrices in 2D and 3D. \n",
    "\n",
    "### 1.1) Calculating 2D rotation matrices (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b077b00-bf16-44d7-988e-27cf380b2a3d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.1.1) \n",
    "Calculate the rotation matrix representing a rotation of $\\theta=90^\\circ$.\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "50976ae0-2716-41ae-8690-d6987cc61d83",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 2D numpy array\n",
    "R_111 = np.array([[0, -1],\n",
    "                  [1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344bf58e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.1.2) \n",
    "Calculate the rotation matrix representing a rotation of $\\theta=180^\\circ$.\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d9ad7927",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 2D numpy array\n",
    "R_112 = np.array([[-1, 0], \n",
    "                  [0, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bfb195",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.1.3) \n",
    "Calculate the rotation matrix representing a rotation of $\\theta=270^\\circ$.\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2a20cb9d",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 2D numpy array\n",
    "R_113 = np.array([[0, 1], \n",
    "                  [-1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd65169",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.1.4) \n",
    "Calculate the rotation matrix representing a rotation of $\\theta=0^\\circ$.\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "337cb9f6",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 2D numpy array\n",
    "R_114 = np.array([[1, 0], \n",
    "                  [0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3814f7",
   "metadata": {},
   "source": [
    "### 1.2) Calculating 2D homogeneous transformation matrices (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62170472",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.2.1) \n",
    "Calculate the homogeneous transformation matrix representing a rotation of $\\theta=45^\\circ$ and a translation of 3 units in the $x$ direction. \n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e6eebe2b",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 2D numpy array\n",
    "X_121 = np.array([[cos(pi/4), -sin(pi/4), 3], \n",
    "                  [sin(pi/4), cos(pi/4), 0],\n",
    "                  [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be619f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.2.2) \n",
    "Calculate the homogeneous transformation matrix representing a rotation of $\\theta=120^\\circ$ and a translation of 2 units in the $x$ direction and 1 unit in the $y$ direction.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "da394122",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 2D numpy array\n",
    "X_122 = np.array([[cos(2*pi/3), -sin(2*pi/3), 2], \n",
    "                  [sin(2*pi/3), cos(2*pi/3), 1],\n",
    "                  [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a880cf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.2.3) \n",
    "Calculate the homogeneous transformation matrix representing a rotation of $\\theta=210^\\circ$ and a translation of 4 units in the direction of $45^\\circ$ above the $x$ axis. \n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1952d06",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 2D numpy array\n",
    "X_123 = np.array([[cos(7*pi/6), -sin(7*pi/6), 4*cos(pi/4)], \n",
    "                  [sin(7*pi/6), cos(7*pi/6), 4*sin(pi/4)],\n",
    "                  [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d6772",
   "metadata": {},
   "source": [
    "### 1.3) Calculating 3D rotation representations (20 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07616284",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.3.1) \n",
    "Calculate the rotation matrix corresponding to a $\\theta=30^\\circ$ rotation about the $x$ axis.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df512a5",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 2D numpy array\n",
    "R_131 = np.array([[1, 0, 0], \n",
    "                  [0, cos(pi/6), -sin(pi/6)],\n",
    "                  [0, sin(pi/6), cos(pi/6)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e865f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.3.2) \n",
    "Calculate the rotation matrix corresponding to an extrinsic XYZ roll-pitch-yaw of $90^\\circ$, $180^\\circ$, and $270^\\circ$, respectively.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1846debc",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 2D numpy array\n",
    "R_132 = np.array([[0, 0, -1],\n",
    "                  [1, 0, 0],\n",
    "                  [0, -1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc689f3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.3.3) \n",
    "Calculate the unit quaternion corresponding to the roll-pitch-yaw in the previous part. *Hint: you may find it useful to refer to the formula in the slides for converting between unit quaternions and rotation matrices.*\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5f800f48",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 1D numpy array\n",
    "q_133 = np.array([0.5, -0.5, -0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cee58cf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.3.4) \n",
    "Calculate the axis-angle representation corresponding to the same roll-pitch-yaw in the previous part. *Hint: you may find it useful to refer to the formula in the slides for converting between unit quaternions and axis-angle representations.*\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4b983722",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 1D numpy array\n",
    "aa_134 = 2*acos(0.5) * np.array([-0.5/sqrt(1-0.25), -0.5/sqrt(1-0.25), 0.5/sqrt(1-0.25)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699d884",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.3.5) \n",
    "Give an example of two 3D rotation matrices $R_1$ and $R_2$ such that $R_1\\cdot R_2 \\neq R_2 \\cdot R_1$.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e839b9",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Express your answer as two 2D numpy arrays\n",
    "R_1351 = np.array([[1, 0, 0],\n",
    "                   [0, 0, -1],\n",
    "                   [0, 1, 0]])\n",
    "R_1352 = np.array([[0, 0, 1],\n",
    "                   [0, 1, 0],\n",
    "                   [-1, 0, 0]])\n",
    "\n",
    "R_1351 @ R_1352 == R_1352 @ R_1351"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a66366",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.3.6) \n",
    "Give an example of two 3D (non-idendity) rotation matrices $R_1$ and $R_2$ such that $R_1\\cdot R_2 = R_2 \\cdot R_1$. \n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "58e6c16c",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Express your answer as two 2D numpy arrays\n",
    "R_1361 = np.array([[1, 0, 0],\n",
    "                   [0, 0, -1],\n",
    "                   [0, 1, 0]])\n",
    "R_1362 = np.array([[1, 0, 0],\n",
    "                   [0, 0, 1],\n",
    "                   [0, -1, 0]])\n",
    "R_1361 @ R_1362 == R_1362 @ R_1361"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f50b6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.3.7) \n",
    "Following our convention for extrinsic XYZ roll-pitch-yaw, derive a simplified expression for the rotation matrix resulting from a pitch of $p=-\\pi/2$, a roll of $r$, and a yaw of $y$. Your answer should be a python function that takes in a roll `r` and a yaw `y` and returns a 3D rotation matrix. Work out the expression by hand and directly return the simplified rotation matrix (i.e., don't write a function that computes the product of three rotation matrices).\n",
    "\n",
    "\n",
    "\n",
    "*Hint: use the following two angle sum trigonometric identities:*\n",
    "$$\\begin{aligned}\n",
    "    \\sin(\\alpha+\\beta) &= \\sin\\alpha\\cos\\beta + \\cos\\alpha\\sin\\beta\\\\\n",
    "    \\cos(\\alpha+\\beta) &= \\cos\\alpha\\cos\\beta - \\sin\\alpha\\sin\\beta\n",
    "\\end{aligned}$$\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "58d7c9bf",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def R_r_halfpi_y_137(r, y):\n",
    "    return np.array([[0, -cos(y)*sin(r)-sin(y)*cos(r), sin(y)*sin(r)-cos(y)*cos(r)],\n",
    "                     [0, cos(y)*cos(r)-sin(r)*sin(y), -sin(y)*cos(r)-cos(y)*sin(r)],\n",
    "                     [1, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d331dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the resulting matrix, how does a change in $r$ compare to a change in $y$?\n",
    "\n",
    "a. $r$ and $y$ rotate about orthogonal axes\\\n",
    "b. $r$ and $y$ cause rotations about the same axis\\\n",
    "c. $r$ and $y$ rotate in opposite directions\\\n",
    "d. $r$ and $y$ rotate about different but not orthogonal axes\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "595ba8d8",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Enter your answer as a lower-case Python string (e.g., \"a\")\n",
    "ans_1371 = \"b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348d212",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What does this tell us about roll-pitch-yaw as a representation for rotations? Choose all that apply.\n",
    "\n",
    "a. Some roll-pitch-yaw configurations result in invalid rotations\\\n",
    "b. At some configurations for one angle, the two remaining angles represent the same rotation\\\n",
    "c. At some configurations for one angle, it is not possible to rotate about one axis\n",
    "d. Roll-pitch-yaw should not be used\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "4aa1180c",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Enter your answer as a list of lower-case Python strings (e.g., [\"a\", \"b\", \"c\", \"d\"] for all choices or [] for no choice)\n",
    "ans_1372 = [\"b\", \"c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc7b768",
   "metadata": {},
   "source": [
    "## 2) Rigid motions of objects (20 pts)\n",
    "\n",
    "All previous questions asked about rotations and transformations as abstract objects, not tied to a particular physical interpretation. In this problem, we will apply rotations and transformations to objects to understand their position and/or orientation in a chosen coordinate frame.\n",
    "\n",
    "For all questions in this section you're welcome to work out the solutions by hand and enter the final answer or write Python code to compute the answers directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae177c1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.1) 2D change of view-point\n",
    "\n",
    "Some point $A$ is displaced from the origin of the world-coordinate frame $W$ by $3$ units in $W$'s $x$ direction and $4$ units in $W$'s $y$ direction. There is another coordinate frame $O$, which is displaced from $W$ by $2$ units in the negative $x$ direction of $W$ and $1$ unit in the $y$ direction of $W$, and rotated by $30^\\circ$ counter-clockwise. Find the coordinates of point $A$ relative to frame $O$ expressed in frame $O$.\n",
    "\n",
    "Your answer should be a $2\\times 1$ numpy array.\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f29dd24f",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 2x1 numpy array\n",
    "p_OA_21 = np.array([[5*cos(pi/6)+3*cos(pi/3)],\n",
    "                    [3*cos(pi/6)-5*cos(pi/3)]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a585f4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.2) 3D change of view-point\n",
    "\n",
    "An object $O$ has an attached coordinate frame $O$, whose origin is at $(2,1,5)$ relative to the world frame $W$. Frame $O$ is rotated relative to $W$ by $90^\\circ$ about the $z$ axis of $W$. There is a point $A$ in object $O$ at position $(1,0,0)$ relative to $O$. Find the world coordinates of point $A$. \n",
    "\n",
    "Your answer should be a $3\\times 1$ numpy array.\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "51c2d0d8",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 3x1 numpy array\n",
    "p_A_22 = np.array([[2],\n",
    "                   [2],\n",
    "                   [5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d6674d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.3) 2D action\n",
    "\n",
    "A robot sarts at position (1,2) in the world frame, with its $x$-axis facing $45^\\circ$ above the world's $x$ axis. The robot's gripper is at position $(0.1, 0.1)$ in the robot's frame. The robot moves forward 3 units along its $x$ axis and then rotates counter-clockwise by $90^\\circ$. What is the final position of the robot's gripper in the world frame?\n",
    "\n",
    "Your answer should be a $2\\times 1$ numpy array.\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3608c39f",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 2x1 numpy array\n",
    "p_Gnew_23 = np.array([[2.9798],\n",
    "                      [4.1213]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285f047",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.4) 3D action\n",
    "\n",
    "Suppose we have a robot arm with a single spherical joint attached to a fixed table, connected to a link of length 2. The world coordinate frame is at the base of the link. Initially, the link is facing in the $x$ direction of the world frame and the gripper frame is rotated from the world frame by $-90^\\circ$ about the $z$ axis, such that the $y$ frame points away from the gripper. The robot is grasping a box, whose center of mass is at position $(0, 0, 0.2)$ in the gripper frame. Calculate the position of the center of mass in the world frame after applying a rotation on the spherical joint given by:\n",
    "$$R =\\begin{pmatrix}\n",
    "    0.306 & 0.787 & 0.536\\\\\n",
    "    -0.521 & 0.61 & -0.598\\\\\n",
    "    -0.797 & -0.096 & 0.597\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Your answer should be a $3\\times 1$ numpy array.\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "992bef7e",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 3x1 numpy array\n",
    "p_G_24 = np.array([[0.7192],\n",
    "                   [-1.1616],\n",
    "                   [-1.4746]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc183806",
   "metadata": {},
   "source": [
    "## 3) Pick-and-place with floating hand (50 pts)\n",
    "\n",
    "In the following problem, we will explore the initial steps toward defining a pick-and-place trajectory for a robot arm. This week, we will move around a floating hand. In particular, we will be working with the Franka Panda arm (or, this week, the Franka Panda hand). \n",
    "\n",
    "We will make use of the `MuJoCo` physics engine, which you can install locally via `pip install mujoco`. We will use `mediapy` to visualize our robot; install via `pip install mediapy`.\n",
    "\n",
    "We will start with a simulated world that contains three objects: the robot hand, a table, and a red block. Our goal will be to pick the red block off the table and place it in some target location on the table. \n",
    "\n",
    "We will achieve this by moving the hand through 5 poses:\n",
    "- Floating above the object\n",
    "- Grasping the object\n",
    "- Lifting the object\n",
    "- Floating above the target location\n",
    "- Placing the object\n",
    "\n",
    "Start by downloading the `assets.zip` file from the Brightspace assignment, unzip it and place the `assets/` directory in the same directory that contains your `hw3.ipynb` file. These `assets` contain a `panda_hand.mjcf` file, which describes how the three objects in the world relate to each other. Then, run the code cell below, which loads the `.mjcf` file and renders the world in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "65ebe2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"show_images\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><img width=\"640\" height=\"480\" style=\"image-rendering:auto; object-fit:cover;\" src=\"data:image/png;base64,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\"/></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mujoco\n",
    "import mediapy as media\n",
    "import os\n",
    "import glfw\n",
    "\n",
    "def has_valid_renderer():\n",
    "    \"\"\"Checks if OpenGL can be initialized successfully.\"\"\"\n",
    "    # Try initializing GLFW\n",
    "    if not glfw.init():\n",
    "        print(\"GLFW initialization failed. No valid renderer.\")\n",
    "        return False\n",
    "    \n",
    "    # Try creating a hidden window to test OpenGL context creation\n",
    "    window = glfw.create_window(640, 480, \"Renderer Test\", None, None)\n",
    "    if not window:\n",
    "        print(\"GLFW could not create an OpenGL context. No valid renderer.\")\n",
    "        glfw.terminate()\n",
    "        return False\n",
    "    \n",
    "    glfw.make_context_current(window)\n",
    "    renderer_available = True  # If we reach this point, rendering should work\n",
    "\n",
    "    # Cleanup\n",
    "    glfw.destroy_window(window)\n",
    "    glfw.terminate()\n",
    "    return renderer_available\n",
    "\n",
    "def render_state(model, data):\n",
    "    if not has_valid_renderer():\n",
    "        print(\"Error rendering the scene. Make sure you have a valid OpenGL installation.\")\n",
    "        return\n",
    "\n",
    "    mujoco.mj_forward(model, data)\n",
    "    with mujoco.Renderer(model, height=480, width=640) as renderer:\n",
    "        renderer.update_scene(data, \"front_view\")  # Ensure scene is updated with final simulation state\n",
    "        media.show_image(renderer.render())\n",
    "\n",
    "# Define the MJCF path and mesh directory\n",
    "mjcf_path = 'assets/assets/Panda/panda_hand.mjcf'\n",
    "mesh_dir = 'assets/assets/Panda/meshes/collision/'\n",
    "\n",
    "# Load mesh files into a dictionary\n",
    "assets = {}\n",
    "for file_name in os.listdir(mesh_dir):\n",
    "    file_path = os.path.join(mesh_dir, file_name)\n",
    "    with open(file_path, 'rb') as f:\n",
    "        assets[f'meshes/collision/{file_name}'] = f.read()\n",
    "\n",
    "# Load the MuJoCo model\n",
    "model = mujoco.MjModel.from_xml_path(mjcf_path, assets=assets)\n",
    "data = mujoco.MjData(model)\n",
    "\n",
    "# Call mj_forward to initialize the state\n",
    "mujoco.mj_forward(model, data)\n",
    "\n",
    "# Get actuator IDs\n",
    "ctrl1_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_ACTUATOR, \"panda_finger_joint1_ctrl\")\n",
    "ctrl2_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_ACTUATOR, \"panda_finger_joint2_ctrl\")\n",
    "\n",
    "# Check if actuator IDs were found\n",
    "if ctrl1_id == -1 or ctrl2_id == -1:\n",
    "    raise ValueError(\"Actuators not found! Check the MJCF actuator names.\")\n",
    "\n",
    "# Apply control targets\n",
    "target_pos = 0.04  # Open fingers\n",
    "data.ctrl[ctrl1_id] = target_pos\n",
    "data.ctrl[ctrl2_id] = target_pos\n",
    "\n",
    "# Step the simulation multiple times so fingers reach open position\n",
    "for _ in range(100): \n",
    "    mujoco.mj_step(model, data)\n",
    "\n",
    "# Render the scene\n",
    "render_state(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74f6e33",
   "metadata": {},
   "source": [
    "The world coordinate frame is centered at the bottom of the center of the table. The $x$ axis points to right, the $y$ axis points into the picture, and the $z$ axis points up. The robot is initially in position $(-0.5, 0, 1.5)$ in world coordinates. The gripper's $x$ axis points toward the world's $y$ axis, its $y$ axis points toward the world's $x$ axis, and its $z$ axis points toward the world's $-z$ axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb5647",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 3.1)\n",
    "With this, we can construct the rotation matrix $R^\\text{G}$. Please provide the matrix below.\n",
    "\n",
    "*Hint: recall how the columns of the rotation matrix relate to the axes of the resulting frame.*\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e619747e",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your answer as a 3x3 numpy array\n",
    "R_G_31 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884c032",
   "metadata": {},
   "source": [
    "In the following parts, we will compose transformations to compute desired poses for the gripper in the world frame. For example, if we wish to place the gripper at some relative pose w.r.t. the block ${}^{B} X^{G}$, and we know that the block's world pose is $X^{B}$, then we can set the gripper's pose to $X^{G} = X^{B} \\cdot {}^{B} X^{G}$.\n",
    "\n",
    "For all transformations, you should leverage MuJoCo's transformation functions. These functions are not very Pythonic: instead of returning arrays like you would in Python, they require you to pass arrays as arguments which will get filled with the outputs of the function. In particular, you will find the following useful:\n",
    "- `mujoco.mju_mat2Quat(output_quat, Rmat)` -- converts a rotation matrix to a unit quaternion:\n",
    "    - `output_quat` is a `(4,)` numpy array, which will contain the result of the converstion from rotation matrix to quaternion\n",
    "    - `Rmat` is a `(9,)` numpy array representing the rotation matrix to convert. (To get your `(3,3)` matrix into the correct shape, use `Rmat.reshape(9)`.)\n",
    "- `mujoco.mju_mulPose(output_pos, output_quat, pos1, quat1, pos2, quat2)` -- computes the pose resulting from multiplying two poses:\n",
    "    - `output_pos` is a `(3,)` numpy array, which will contain the position resulting from the product of the transformations `(pos1, quat1)` $\\cdot$ `(pos2, quat2)`\n",
    "    - `output_quat` is a `(4,)` numpy array, which will contain the orientation resulting from the product of the transformations `(pos1, quat1)` $\\cdot$ `(pos2, quat2)`\n",
    "    - `pos1`: the position of the first transform, as a `(3,)` numpy array\n",
    "    - `quat1`: the orientation of the first transform, as a `(4,)` numpy array representing a unit quaternion\n",
    "    - `pos2`: the position of the second transform, as a `(3,)` numpy array\n",
    "    - `quat2`: the orientation of the second transform, as a `(4,)` numpy array representing a unit quaternion\n",
    "- `mujoco.mju_trnVecPose(output_pos, pos, quat, x)` -- transforms a position by multiplying it by a transform\n",
    "    - `output_pos` is a `(3,)` numpy array, which will contain the position resulting from applying the transformation `(pos, quat)` to position `x`\n",
    "    - `pos`: the position component of the transform, as a `(3,)` numpy array\n",
    "    - `quat`: the orientation component of the transform, as a `(4,)` numpy array representing a unit quaternion\n",
    "- `mujoco.mju_negPose(out_pos, out_quat, pos, quat)` -- inverts a transform\n",
    "    - `out_pos`: a `(3,)` numpy array, which will contain the position resulting from inverting the transformation `(pos, quat)` \n",
    "    - `out_quat`: a `(4,)` numpy array, which will contain the position resulting from inverting the transformation `(pos, quat)`\n",
    "    - `pos`: the position component of the transform to invert, as a `(3,)` numpy array\n",
    "    - `quat`: the orientation component of the transform to invert, as a `(4,)` numpy array representing a unit quaternion\n",
    "\n",
    "To obtain the current position and orientation of an object in the world frame, you may use `model.body(<object_name>).pos/quat`, where `<object_name>` will be `panda_hand` for the gripper and `block` for the block. To set the gripper's position, you may use `data.mocap_pos[0] = pos`, and to set the gripper's orientation you may use `data.mocap_quat[0] = quat`. \n",
    "\n",
    "To visualize the resulting gripper pose for debugging purposes, you may use the `render_state` function defined in the previous code cell, which takes as input the `model` and `data` objects created in the same cell.\n",
    "\n",
    "### 3.2)\n",
    "The first waypoint in our path for picking-and-placing the block is to set the gripper floating above the block. We will set the gripper to be 0.5 units above the block on the $z$ axis of the block, and its orientation to be: $x$ axis aligned with block's $y$ axis, $y$ axis aligned with block's $x$ axis, and $z$ axis aligned with block's $-z$ axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709a627",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.2.1)\n",
    "Find the block's current position and orientation as a quaternion in world coordinates, $X^{B}$.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "05d194e9",
   "metadata": {
    "otter": {
     "tests": [
      "q3.2.1"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your position as a (3,) numpy array and your orientation as a (4,) numpy array\n",
    "p_B_321 = ...\n",
    "quat_B_321 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c81b741",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.2.2)\n",
    "Compute the desired position and orientation (as a quaternion) of the gripper in the floating configuration relative to the block, ${}^{B} X^{G_\\text{float}}$. You may wish to first find the matrix representation of the rotation and then use MuJoCo's functions to convert that to a quaternion.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "04179655",
   "metadata": {
    "otter": {
     "tests": [
      "q3.2.2"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Express your position as a (3,) numpy array and your orientation as a (4,) numpy array\n",
    "p_BGfloat_322 = ...\n",
    "quat_BGfloat_322 = np.empty(4)  # Initialize the quaternion\n",
    "#*** YOUR CODE HERE ***\n",
    "# Fill in the values of quat_BGfloat_322\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba4a03",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.2.3)\n",
    "Find the desired world position and orientation (as a quaternion) of the gripper in world coordinates, $X^{G_\\text{float}}$.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "71734dc1",
   "metadata": {
    "otter": {
     "tests": [
      "q3.2.3"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Express your position as a (3,) numpy array and your orientation as a (4,) numpy array\n",
    "p_Gfloat_323 = np.empty(3)     # Initialize the position\n",
    "quat_Gfloat_323 = np.empty(4)  # Initialize the quaternion\n",
    "#*** YOUR CODE HERE ***\n",
    "# Fill in the values of p_Gfloat_323 and quat_Gfloat_323\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820560b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.2.4)\n",
    "Set the gripper pose to the desired floating pose and visualize it to make sure that it is correct. \n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3948c572",
   "metadata": {
    "otter": {
     "tests": [
      "q3.2.4"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'ellipsis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[188], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set the position and orientation of the mocap object\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmocap_pos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mmocap_quat[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m## Do *not* modify the code below\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'ellipsis'"
     ]
    }
   ],
   "source": [
    "# Set the position and orientation of the mocap object\n",
    "data.mocap_pos[0] = ...\n",
    "data.mocap_quat[0] = ...\n",
    "\n",
    "## Do *not* modify the code below\n",
    "render_state(model, data)\n",
    "ans_324 = np.r_[data.mocap_pos[0], data.mocap_quat[0]] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fbb692",
   "metadata": {},
   "source": [
    "### 3.3)\n",
    "Next, we will lower the gripper to be 0.12 units above the block. Given the relative offsets of the block's origin (which is at the center) and the gripper's origin (which is at the top), this should roughly place the gripper's fingers centered around the block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79411360",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.3.1)\n",
    "\n",
    "Compute the desired position and orientation (as a quaternion) of the gripper at desired new picking configuration relative to the previous floating configuration, ${}^{G_\\text{float}} X^{G_\\text{pick}}$. \n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f71f6a60",
   "metadata": {
    "otter": {
     "tests": [
      "q3.3.1"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your position as a (3,) numpy array and your orientation as a (4,) numpy array\n",
    "p_GfloatGpick_331 = ...\n",
    "quat_GfloatGpick_331 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4fe91",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.3.2)\n",
    "Compute the desired position and orientation (as a quaternion) of the gripper at the picking configuration in world coordinates, $X^{G_\\text{pick}}$.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "220b73e7",
   "metadata": {
    "otter": {
     "tests": [
      "q3.3.2"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Express your position as a (3,) numpy array and your orientation as a (4,) numpy array\n",
    "p_Gpick_332 = np.empty(3)     # Initialize the position\n",
    "quat_Gpick_332 = np.empty(4)  # Initialize the quaternion\n",
    "#*** YOUR CODE HERE ***\n",
    "# Fill in the values of p_Gpick_332 and quat_Gpick_332\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd480a1c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.3.3)\n",
    "Set the gripper pose to the desired picking pose and visualize it to make sure that it is correct. \n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "82abe794",
   "metadata": {
    "otter": {
     "tests": [
      "q3.3.3"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'ellipsis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[191], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set the position and orientation of the mocap object\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmocap_pos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mmocap_quat[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m## Do *not* modify the code below\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'ellipsis'"
     ]
    }
   ],
   "source": [
    "# Set the position and orientation of the mocap object\n",
    "data.mocap_pos[0] = ...\n",
    "data.mocap_quat[0] = ...\n",
    "\n",
    "## Do *not* modify the code below\n",
    "render_state(model, data)\n",
    "ans_333 = np.r_[data.mocap_pos[0], data.mocap_quat[0]] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b39550",
   "metadata": {},
   "source": [
    "### 3.4)\n",
    "\n",
    "To avoid over-complicating things, we assume that just by reaching the block, the gripper grasps the block. (Physically grasping the block is non-trivial, but we won't get into that in this course.) With that, the next step is to set the gripper back to the floating position, now holding the block. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa02026",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.4.1) \n",
    "For the remaining questions, and for visualization in this part, it will be useful to calculate the pose of the \n",
    "block relative to the gripper while the gripper is held, ${}^{B} X^{G_\\text{pick}}$. With a proper grasp, this relative pose is constant until the block is placed. \n",
    "\n",
    "Compute the desired position and orientation (as a quaternion). *Hint: recall that the orientation of the gripper didn't change between floating and picking.*\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a7ecc641",
   "metadata": {
    "otter": {
     "tests": [
      "q3.4.1"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your position as a (3,) numpy array and your orientation as a (4,) numpy array\n",
    "\n",
    "p_BGpick_341 = ...\n",
    "quat_BGpick_341 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0a584f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.4.2) \n",
    "Now simply set the position and orientation of the gripper to match the previous floating configuration.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "adc748b6",
   "metadata": {
    "otter": {
     "tests": [
      "q3.4.2"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'ellipsis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[193], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set the position and orientation of the mocap object\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmocap_pos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mmocap_quat[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# The next few lines \"attach\" the block to the gripper.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# This is not required for obtaining points in the \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# assignment, but is included for visualization purposes.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# This will only \"look right\" if your answers up to this\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# point are correct.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'ellipsis'"
     ]
    }
   ],
   "source": [
    "# Set the position and orientation of the mocap object\n",
    "data.mocap_pos[0] = ...\n",
    "data.mocap_quat[0] = ...\n",
    "\n",
    "# The next few lines \"attach\" the block to the gripper.\n",
    "# This is not required for obtaining points in the \n",
    "# assignment, but is included for visualization purposes.\n",
    "# This will only \"look right\" if your answers up to this\n",
    "# point are correct.\n",
    "p_GpickB_342 = np.empty(3)\n",
    "quat_GpickB_342 = np.empty(4)\n",
    "mujoco.mju_negPose(p_GpickB_342, quat_GpickB_342, p_BGpick_341, quat_BGpick_341)\n",
    "\n",
    "p_Bfloat = np.empty(3)\n",
    "quat_Bfloat = np.empty(4)\n",
    "# Compute the pose of the block int he world frame by \n",
    "# composing the pose of the gripper in the world frame\n",
    "# and the relative pose of the gripper w.r.t. the \n",
    "# block \n",
    "mujoco.mju_mulPose(p_Bfloat, quat_Bfloat, p_Gfloat_323, quat_Gfloat_323, p_GpickB_342, quat_GpickB_342)\n",
    "model.body(\"block\").pos = p_Bfloat\n",
    "model.body(\"block\").quat = quat_Bfloat\n",
    "\n",
    "## Do *not* modify the code below\n",
    "render_state(model, data)\n",
    "ans_342 = np.r_[data.mocap_pos[0], data.mocap_quat[0]] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad13915",
   "metadata": {},
   "source": [
    "### 3.5)\n",
    "\n",
    "The next step is to move the gripper so that the block hovers above its final desired orientation. Suppose we want the block to end up at position $(-0.3, -0.2, 1.03)$, with its orientation aligned with the world frame. The goal of this stage is to move the gripper so that the block is $0.5$ units above its target position in the $z$ axis, and aligned with its final desired orientation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa08c531",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.5.1) \n",
    "Calculate the desired position and orientation (as a quaternion) of the block in world coordinates at the hovering stage, $X^{B_\\text{hover}}$.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4fc4e3b5",
   "metadata": {
    "otter": {
     "tests": [
      "q3.5.1"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your position as a (3,) numpy array and your orientation as a (4,) numpy array\n",
    "\n",
    "p_Bhover_341 = ...\n",
    "quat_Bhover_341 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82bab67",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.5.2) \n",
    "Calculate the desired position and orientation (as a quaternion) of the gripper in world coordinates at the hovering stage, $X^{G_\\text{hover}}$.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f6d8ba9f",
   "metadata": {
    "otter": {
     "tests": [
      "q3.5.2"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Express your position as a (3,) numpy array and your orientation as a (4,) numpy array\n",
    "p_Ghover_352 = np.empty(3)     # Initialize the position\n",
    "quat_Ghover_352 = np.empty(4)  # Initialize the quaternion\n",
    "#*** YOUR CODE HERE ***\n",
    "# Fill in the values of p_Ghover_352 and quat_Ghover_352\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf99b91e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.5.3)\n",
    "Set the gripper pose to the desired hovering pose and visualize it to make sure that it is correct. \n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3eb085a6",
   "metadata": {
    "otter": {
     "tests": [
      "q3.5.3"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'ellipsis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[197], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set the position and orientation of the mocap object\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmocap_pos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mmocap_quat[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# The next few lines \"attach\" the block to the gripper.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# This is not required for obtaining points in the \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# assignment, but is included for visualization purposes.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# This will only \"look right\" if your answers up to this\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# point are correct.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'ellipsis'"
     ]
    }
   ],
   "source": [
    "# Set the position and orientation of the mocap object\n",
    "data.mocap_pos[0] = ...\n",
    "data.mocap_quat[0] = ...\n",
    "\n",
    "# The next few lines \"attach\" the block to the gripper.\n",
    "# This is not required for obtaining points in the \n",
    "# assignment, but is included for visualization purposes.\n",
    "# This will only \"look right\" if your answers up to this\n",
    "# point are correct.\n",
    "p_Bhover = np.empty(3)\n",
    "quat_Bhover = np.empty(4)\n",
    "# Compute the pose of the block int he world frame by \n",
    "# composing the pose of the gripper in the world frame\n",
    "# and the relative pose of the gripper w.r.t. the \n",
    "# block \n",
    "mujoco.mju_mulPose(p_Bhover, quat_Bhover, p_Ghover_352, quat_Ghover_352, p_GpickB_342, quat_GpickB_342)\n",
    "model.body(\"block\").pos = p_Bhover\n",
    "model.body(\"block\").quat = quat_Bhover\n",
    "\n",
    "## Do *not* modify the code below\n",
    "render_state(model, data)\n",
    "ans_353 = np.r_[data.mocap_pos[0], data.mocap_quat[0]] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47415369",
   "metadata": {},
   "source": [
    "### 3.6)\n",
    "Finally, we will lower the gripper so that the block is at the target position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd6aaa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.6.1)\n",
    "\n",
    "Compute the desired position and orientation (as a quaternion) of the gripper at desired new placing configuration relative to the previous hovering configuration, ${}^{G_\\text{hover}} X^{G_\\text{place}}$. \n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "dca4c807",
   "metadata": {
    "otter": {
     "tests": [
      "q3.6.1"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Express your position as a (3,) numpy array and your orientation as a (4,) numpy array\n",
    "p_GhoverGplace_361 = ...\n",
    "quat_GhoverGplace_361 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926e6ce",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.6.2)\n",
    "Compute the desired position and orientation (as a quaternion) of the gripper at the placing configuration in world coordinates, $X^{G_\\text{place}}$.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4d0b8fd8",
   "metadata": {
    "otter": {
     "tests": [
      "q3.6.2"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Express your position as a (3,) numpy array and your orientation as a (4,) numpy array\n",
    "p_Gplace_362 = np.empty(3)     # Initialize the position\n",
    "quat_Gplace_362 = np.empty(4)  # Initialize the quaternion\n",
    "#*** YOUR CODE HERE ***\n",
    "# Fill in the values of p_Gplace_362 and quat_Gplace_362\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a35d8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.6.3)\n",
    "Set the gripper pose to the desired picking pose and visualize it to make sure that it is correct. \n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "eacb2ff3",
   "metadata": {
    "otter": {
     "tests": [
      "q3.6.3"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'ellipsis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[201], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set the position and orientation of the mocap object\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmocap_pos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mmocap_quat[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# The next few lines \"attach\" the block to the gripper.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# This is not required for obtaining points in the \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# assignment, but is included for visualization purposes.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# This will only \"look right\" if your answers up to this\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# point are correct.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'ellipsis'"
     ]
    }
   ],
   "source": [
    "# Set the position and orientation of the mocap object\n",
    "data.mocap_pos[0] = ...\n",
    "data.mocap_quat[0] = ...\n",
    "\n",
    "# The next few lines \"attach\" the block to the gripper.\n",
    "# This is not required for obtaining points in the \n",
    "# assignment, but is included for visualization purposes.\n",
    "# This will only \"look right\" if your answers up to this\n",
    "# point are correct.\n",
    "p_Bplace = np.empty(3)\n",
    "quat_Bplace = np.empty(4)\n",
    "# Compute the pose of the block int he world frame by \n",
    "# composing the pose of the gripper in the world frame\n",
    "# and the relative pose of the gripper w.r.t. the \n",
    "# block \n",
    "mujoco.mju_mulPose(p_Bplace, quat_Bplace, p_Gplace_362, quat_Gplace_362, p_GpickB_342, quat_GpickB_342)\n",
    "model.body(\"block\").pos = p_Bplace\n",
    "model.body(\"block\").quat = quat_Bplace\n",
    "\n",
    "## Do *not* modify the code below\n",
    "render_state(model, data)\n",
    "ans_363 = np.r_[data.mocap_pos[0], data.mocap_quat[0]]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb00186",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Fill out the answers to all questions and submit your file hw3.ipynb to the HW3 assignment on Gradescope. You are free to resubmit as many times as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "36cb1a48",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running your submission against local test cases...\n",
      "\n",
      "\n",
      "Your submission received the following results when run against available test cases:\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <p>\n",
       "                        Your submission has been exported. Click\n",
       "                        <a href=\"hw3_2025_02_17T18_54_33_812596.zip\" download=\"hw3_2025_02_17T18_54_33_812596.zip\" target=\"_blank\">here</a> to download\n",
       "                        the zip file.\n",
       "                    </p>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77842a55",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "hw3",
   "tests": {
    "q1.1.1": {
     "name": "q1.1.1",
     "points": 1,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.1.2": {
     "name": "q1.1.2",
     "points": 1,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.1.3": {
     "name": "q1.1.3",
     "points": 1,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.1.4": {
     "name": "q1.1.4",
     "points": 1,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.2.1": {
     "name": "q1.2.1",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.2.2": {
     "name": "q1.2.2",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.2.3": {
     "name": "q1.2.3",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.1": {
     "name": "q1.3.1",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.2": {
     "name": "q1.3.2",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.3": {
     "name": "q1.3.3",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.4": {
     "name": "q1.3.4",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.5": {
     "name": "q1.3.5",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.6": {
     "name": "q1.3.6",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.7": {
     "name": "q1.3.7",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.7.1": {
     "name": "q1.3.7.1",
     "points": 1,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.7.2": {
     "name": "q1.3.7.2",
     "points": 1,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.2": {
     "name": "q2.2",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.3": {
     "name": "q2.3",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.4": {
     "name": "q2.4",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.1": {
     "name": "q3.1",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.2.1": {
     "name": "q3.2.1",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.2.2": {
     "name": "q3.2.2",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.2.3": {
     "name": "q3.2.3",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.2.4": {
     "name": "q3.2.4",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.3.1": {
     "name": "q3.3.1",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.3.2": {
     "name": "q3.3.2",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.3.3": {
     "name": "q3.3.3",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.4.1": {
     "name": "q3.4.1",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.4.2": {
     "name": "q3.4.2",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.5.1": {
     "name": "q3.5.1",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.5.2": {
     "name": "q3.5.2",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.5.3": {
     "name": "q3.5.3",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.6.1": {
     "name": "q3.6.1",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.6.2": {
     "name": "q3.6.2",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.6.3": {
     "name": "q3.6.3",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
